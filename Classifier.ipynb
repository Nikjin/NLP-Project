{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c878729b",
      "metadata": {
        "id": "c878729b"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import json\n",
        "import zipfile\n",
        "import urllib.request\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from imblearn import under_sampling, over_sampling\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from imblearn.metrics import classification_report_imbalanced\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#import lightgbm as lgb\n",
        "\n",
        "from sklearn.metrics import (precision_score, recall_score, roc_auc_score, accuracy_score,\n",
        "                             confusion_matrix, precision_recall_curve, roc_curve, brier_score_loss)\n",
        "\n",
        "# from sklearn.externals import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ce8856e6",
      "metadata": {
        "id": "ce8856e6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import lightgbm as lgb\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PAzvWOks3evC"
      },
      "id": "PAzvWOks3evC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8d6fd32",
      "metadata": {
        "id": "f8d6fd32"
      },
      "outputs": [],
      "source": [
        "users_emotion_damf_tox_10 = pd.read_csv('/content/drive/MyDrive/NLP HW/Project/users_emotion_damf_tox_10.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9947eb7d",
      "metadata": {
        "id": "9947eb7d"
      },
      "outputs": [],
      "source": [
        "users_emotion_damf_tox_10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c3b8ec2",
      "metadata": {
        "id": "6c3b8ec2"
      },
      "outputs": [],
      "source": [
        "users_emotion_damf_tox_10.category.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31efbe75",
      "metadata": {
        "id": "31efbe75"
      },
      "outputs": [],
      "source": [
        "def RF_pred(X, y):\n",
        "    # Build models with hyperparameters sets\n",
        "    RSC = RandomizedSearchCV(\n",
        "        estimator=RandomForestClassifier(),\n",
        "        param_distributions={\n",
        "            'n_estimators': range(1, 200, 10),\n",
        "            'max_depth': range(1, 100, 10),\n",
        "            'max_features': ['auto', 'sqrt', 'log2']}, cv=3, scoring='roc_auc', n_jobs=-1)\n",
        "    # Fit RandomizedSearchCV to find best hyperparameters\n",
        "    search_result = RSC.fit(X, y)\n",
        "    print(\"Best using: \", search_result.best_params_, \"Score: \", search_result.best_score_)\n",
        "    # Build models with optimized hyperparameters\n",
        "    model_RF = RandomForestClassifier(\n",
        "        n_estimators=search_result.best_params_[\"n_estimators\"],\n",
        "        max_depth=search_result.best_params_[\"max_depth\"],\n",
        "        max_features=search_result.best_params_[\"max_features\"])\n",
        "    # Split dataset into 5 consecutive folds\n",
        "    kf = KFold(n_splits=3, shuffle=True, random_state=None)\n",
        "    i = 1\n",
        "    for train, test in kf.split(X):\n",
        "        X_train = X.iloc[train,:]\n",
        "        y_train = y.iloc[train,:]\n",
        "        X_test = X.iloc[test]\n",
        "        y_test = y.iloc[test]\n",
        "        model_RF.fit(X_train, y_train)\n",
        "        train_pred = model_RF.predict(X_train)\n",
        "        y_pred = model_RF.predict(X_test)\n",
        "        train_accuracy = accuracy_score(y_train, train_pred)\n",
        "        train_precision = precision_score(y_train, train_pred)\n",
        "        train_recall = recall_score(y_train, train_pred)\n",
        "        train_auc = roc_auc_score(y_train, train_pred)\n",
        "        test_accuracy = accuracy_score(y_test, y_pred)\n",
        "        test_precision = precision_score(y_test, y_pred)\n",
        "        test_recall = recall_score(y_test, y_pred)\n",
        "        test_auc = roc_auc_score(y_test, y_pred)\n",
        "        print('Fold '+ str(i), ':  Training accuracy: ', train_accuracy, 'Testing accuracy: ', test_accuracy)\n",
        "        print('Fold '+ str(i), ':  Training precision: ', train_precision, 'Testing precision: ', test_precision)\n",
        "        print('Fold '+ str(i), ':  Training recall: ', train_recall, 'Testing accuracy: ', test_recall)\n",
        "        print('Fold '+ str(i), ':  Training auc: ', train_auc, 'Testing auc: ', test_auc)\n",
        "        i += 1\n",
        "    return model_RF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "\n",
        "def RF_pred_gpu(X, y):\n",
        "    # Convert pandas dataframes to PyTorch tensors\n",
        "    X_tensor = torch.tensor(X.values, dtype=torch.float32).cuda()\n",
        "    y_tensor = torch.tensor(y.values, dtype=torch.float32).cuda()\n",
        "\n",
        "    # Build models with hyperparameters sets using scikit-learn's RandomizedSearchCV\n",
        "    RSC = RandomizedSearchCV(\n",
        "        estimator=RandomForestClassifier(),\n",
        "        param_distributions={\n",
        "            'n_estimators': list(range(1, 200, 10)),\n",
        "            'max_depth': list(range(1, 100, 10)),\n",
        "            'max_features': ['auto', 'sqrt', 'log2']\n",
        "        },\n",
        "        cv=3, scoring='roc_auc', n_jobs=-1)\n",
        "\n",
        "    # Fit RandomizedSearchCV to find best hyperparameters\n",
        "    search_result = RSC.fit(X, y)\n",
        "    print(\"Best using: \", search_result.best_params_, \"Score: \", search_result.best_score_)\n",
        "\n",
        "    # Build models with optimized hyperparameters\n",
        "    model_RF = RandomForestClassifier(\n",
        "        n_estimators=search_result.best_params_[\"n_estimators\"],\n",
        "        max_depth=search_result.best_params_[\"max_depth\"],\n",
        "        max_features=search_result.best_params_[\"max_features\"])\n",
        "\n",
        "    # Split dataset into 3 consecutive folds\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=None)\n",
        "    i = 1\n",
        "    for train, test in kf.split(X):\n",
        "        X_train = X_tensor[train, :]\n",
        "        y_train = y_tensor[train]\n",
        "        X_test = X_tensor[test, :]\n",
        "        y_test = y_tensor[test]\n",
        "\n",
        "        # Convert PyTorch tensors to NumPy arrays for scikit-learn's RandomForestClassifier\n",
        "        X_train_numpy = X_train.cpu().numpy()\n",
        "        y_train_numpy = y_train.cpu().numpy()\n",
        "        X_test_numpy = X_test.cpu().numpy()\n",
        "        y_test_numpy = y_test.cpu().numpy()\n",
        "\n",
        "        # Fit the model on CPU (scikit-learn's RandomForestClassifier doesn't support GPU)\n",
        "        model_RF.fit(X_train_numpy, y_train_numpy)\n",
        "\n",
        "        # Predictions on CPU\n",
        "        train_pred = model_RF.predict(X_train_numpy)\n",
        "        y_pred = model_RF.predict(X_test_numpy)\n",
        "\n",
        "        # Calculate metrics\n",
        "        train_accuracy = accuracy_score(y_train_numpy, train_pred)\n",
        "        train_precision = precision_score(y_train_numpy, train_pred)\n",
        "        train_recall = recall_score(y_train_numpy, train_pred)\n",
        "        train_auc = roc_auc_score(y_train_numpy, train_pred)\n",
        "\n",
        "        test_accuracy = accuracy_score(y_test_numpy, y_pred)\n",
        "        test_precision = precision_score(y_test_numpy, y_pred)\n",
        "        test_recall = recall_score(y_test_numpy, y_pred)\n",
        "        test_auc = roc_auc_score(y_test_numpy, y_pred)\n",
        "\n",
        "        print('Fold ' + str(i), ':  Training accuracy: ', train_accuracy, 'Testing accuracy: ', test_accuracy)\n",
        "        print('Fold ' + str(i), ':  Training precision: ', train_precision, 'Testing precision: ', test_precision)\n",
        "        print('Fold ' + str(i), ':  Training recall: ', train_recall, 'Testing accuracy: ', test_recall)\n",
        "        print('Fold ' + str(i), ':  Training auc: ', train_auc, 'Testing auc: ', test_auc)\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    return model_RF"
      ],
      "metadata": {
        "id": "vTJr-AAo7FHe"
      },
      "id": "vTJr-AAo7FHe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "150aaf08",
      "metadata": {
        "id": "150aaf08"
      },
      "outputs": [],
      "source": [
        "def DT_pred(X, y):\n",
        "    # Build models with hyperparameters sets\n",
        "    RSC = RandomizedSearchCV(\n",
        "        estimator=DecisionTreeClassifier(),\n",
        "        param_distributions={\n",
        "            'criterion': ['gini', 'entropy'],\n",
        "            'max_depth': range(1, 100, 10),\n",
        "            'max_features': ['auto', 'sqrt', 'log2']},\n",
        "        cv=3, scoring='roc_auc', n_jobs=-1, verbose = True)\n",
        "    # Fit RandomizedSearchCV to find best hyperparameters\n",
        "    search_result = RSC.fit(X, y)\n",
        "    print(\"Best using: \", search_result.best_params_, \"Score: \", search_result.best_score_)\n",
        "    # Build models with optimized hyperparameters\n",
        "    model_DT = DecisionTreeClassifier(\n",
        "        criterion=search_result.best_params_[\"criterion\"],\n",
        "        max_depth=search_result.best_params_[\"max_depth\"],\n",
        "        max_features=search_result.best_params_[\"max_features\"])\n",
        "    # Split dataset into 3 consecutive folds\n",
        "    kf = KFold(n_splits=3, shuffle=True, random_state=None)\n",
        "    i = 1\n",
        "    for train, test in kf.split(X):\n",
        "        X_train = X.iloc[train,:]\n",
        "        y_train = y.iloc[train,:]\n",
        "        X_test = X.iloc[test]\n",
        "        y_test = y.iloc[test]\n",
        "        model_DT.fit(X_train, y_train)\n",
        "        train_pred = model_DT.predict(X_train)\n",
        "        y_pred = model_DT.predict(X_test)\n",
        "        train_accuracy = accuracy_score(y_train, train_pred)\n",
        "        train_precision = precision_score(y_train, train_pred)\n",
        "        train_recall = recall_score(y_train, train_pred)\n",
        "        train_auc = roc_auc_score(y_train, train_pred)\n",
        "        test_accuracy = accuracy_score(y_test, y_pred)\n",
        "        test_precision = precision_score(y_test, y_pred)\n",
        "        test_recall = recall_score(y_test, y_pred)\n",
        "        test_auc = roc_auc_score(y_test, y_pred)\n",
        "        print('Fold '+ str(i), ':  Training accuracy: ', train_accuracy, 'Testing accuracy: ', test_accuracy)\n",
        "        print('Fold '+ str(i), ':  Training precision: ', train_precision, 'Testing precision: ', test_precision)\n",
        "        print('Fold '+ str(i), ':  Training recall: ', train_recall, 'Testing accuracy: ', test_recall)\n",
        "        print('Fold '+ str(i), ':  Training auc: ', train_auc, 'Testing auc: ', test_auc)\n",
        "        i += 1\n",
        "    return model_DT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae2223b7",
      "metadata": {
        "id": "ae2223b7"
      },
      "outputs": [],
      "source": [
        "def LGB_pred(X, y):\n",
        "\n",
        "    # Build models with hyperparameters sets\n",
        "    RSC = RandomizedSearchCV(\n",
        "        estimator=lgb.LGBMClassifier(),\n",
        "        param_distributions = { 'boosting_type': ['gbdt', 'goss', 'dart'],\n",
        "                      'num_leaves': range(10, 500, 25),\n",
        "                      'bagging_fraction': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
        "                      'learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1, 0.3, 0.5],\n",
        "                      'min_data': [200, 300, 400, 500, 600],\n",
        "                      'max_bin': [3, 5, 10, 12, 15, 18, 20, 22],\n",
        "                      'lambda_l1': [1, 10, 20, 30, 40],\n",
        "                      'feature_fraction': [0.5, 0.7, 0.8, 0.9],\n",
        "                      'max_depth': range(1, 50, 10)}, cv=3, scoring='roc_auc', n_jobs=-1)\n",
        "\n",
        "    # Fit RandomizedSearchCV to find best hyperparameters\n",
        "    search_result = RSC.fit(X, y)\n",
        "    print(\"Best: using\", search_result.best_score_, search_result.best_params_)\n",
        "\n",
        "    # Build models with optimized hyperparameters\n",
        "    model_LGB = lgb.LGBMClassifier(\n",
        "        boosting_type=search_result.best_params_[\"boosting_type\"],\n",
        "        num_leaves=search_result.best_params_[\"num_leaves\"],\n",
        "        bagging_fraction=search_result.best_params_[\"bagging_fraction\"],\n",
        "        learning_rate=search_result.best_params_[\"learning_rate\"],\n",
        "        min_data=search_result.best_params_[\"min_data\"],\n",
        "        max_bin=search_result.best_params_[\"max_bin\"],\n",
        "        lambda_l1=search_result.best_params_[\"lambda_l1\"],\n",
        "        feature_fraction=search_result.best_params_[\"feature_fraction\"],\n",
        "        max_depth=search_result.best_params_[\"max_depth\"])\n",
        "\n",
        "\n",
        "    # Split dataset into 5 consecutive folds\n",
        "    kf = KFold(n_splits=3, shuffle=True, random_state=None)\n",
        "\n",
        "    i = 1\n",
        "    for train, test in kf.split(X):\n",
        "        X_train = X.iloc[train,:]\n",
        "        y_train = y.iloc[train,:]\n",
        "        X_test = X.iloc[test]\n",
        "        y_test = y.iloc[test]\n",
        "        model_LGB.fit(X_train, y_train)\n",
        "        train_pred = model_LGB.predict(X_train)\n",
        "        y_pred = model_LGB.predict(X_test)\n",
        "\n",
        "        train_accuracy = accuracy_score(y_train, train_pred)\n",
        "        train_precision = precision_score(y_train, train_pred)\n",
        "        train_recall = recall_score(y_train, train_pred)\n",
        "        train_auc = roc_auc_score(y_train, train_pred)\n",
        "\n",
        "        test_accuracy = accuracy_score(y_test, y_pred)\n",
        "        test_precision = precision_score(y_test, y_pred)\n",
        "        test_recall = recall_score(y_test, y_pred)\n",
        "        test_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "        print('Fold '+ str(i), ':  Training accuracy: ', train_accuracy, 'Testing accuracy: ', test_accuracy)\n",
        "        print('Fold '+ str(i), ':  Training precision: ', train_precision, 'Testing precision: ', test_precision)\n",
        "        print('Fold '+ str(i), ':  Training recall: ', train_recall, 'Testing accuracy: ', test_recall)\n",
        "        print('Fold '+ str(i), ':  Training auc: ', train_auc, 'Testing auc: ', test_auc)\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    return model_LGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "264f3771",
      "metadata": {
        "id": "264f3771"
      },
      "outputs": [],
      "source": [
        "users_emotion_damf_tox_10.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "855d8001",
      "metadata": {
        "id": "855d8001"
      },
      "outputs": [],
      "source": [
        "X = users_emotion_damf_tox_10[['anger', 'anticipation', 'disgust', 'fear', 'joy', 'love',\n",
        "       'optimism', 'pessimism', 'sadness', 'surprise', 'trust', 'None',\n",
        "       'Profanity', 'Identity Attack', 'Insult', 'Threat', 'Toxic', 'care',\n",
        "       'harm', 'fairness', 'cheating', 'loyalty', 'betrayal', 'authority',\n",
        "       'subversion', 'purity', 'degradation']]\n",
        "\n",
        "# X = users_emotion_damf_tox[['anger', 'anticipation', 'disgust', 'fear', 'joy', 'love',\n",
        "#        'optimism', 'pessimism', 'sadness', 'surprise', 'trust', 'None',\n",
        "#        'Profanity', 'Identity Attack', 'Insult', 'Threat', 'Toxic']]\n",
        "y = users_emotion_damf_tox_10[['label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ea9169b",
      "metadata": {
        "id": "3ea9169b"
      },
      "outputs": [],
      "source": [
        "# sm = SMOTE(random_state=4)\n",
        "# X_smote, y_smote = SMOTE().fit_sample(X, y)\n",
        "\n",
        "# print(\"Original data distribution: \")\n",
        "# print(y.label.value_counts())\n",
        "# print(\"SMOTE data distribution: \")\n",
        "# print(y_smote.label.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5eb3145",
      "metadata": {
        "id": "d5eb3145"
      },
      "outputs": [],
      "source": [
        "# data = X_smote\n",
        "# data['label'] = y_smote\n",
        "# data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f7bf2c5",
      "metadata": {
        "id": "2f7bf2c5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76cdb8e8",
      "metadata": {
        "id": "76cdb8e8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8b1852c8",
      "metadata": {
        "id": "8b1852c8"
      },
      "source": [
        "## Building Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bc0ff4b",
      "metadata": {
        "id": "4bc0ff4b"
      },
      "outputs": [],
      "source": [
        "def plot_performance(y_test, y_pred, y_pred_prob):\n",
        "\n",
        "\n",
        "    test_fpr, test_tpr, _ = roc_curve(y_test, y_pred_prob)\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
        "\n",
        "    # ROC Curve\n",
        "    fig = plt.figure(1, figsize=(10,5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(test_fpr, test_tpr, label=\"ROC (area = %0.4f)\" % roc_auc_score(y_test, y_pred), color=\"blue\", lw=2)\n",
        "    plt.plot([0, 1], [0, 1], \"k--\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve\")\n",
        "\n",
        "\n",
        "    # Precision Recall Curve\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(recall, precision, marker='.', color=\"blue\", lw=2)\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title(\"Precision Recall Curve\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3461b3d9",
      "metadata": {
        "id": "3461b3d9"
      },
      "outputs": [],
      "source": [
        "def plot_confusion(y_test, y_pred):\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "#     fig = plt.figure(1, figsize=(10,5))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax =  fig.add_subplot(1,1,1, adjustable='box', aspect=1)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.colorbar()\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "    np.set_printoptions(precision=2)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ca590ab",
      "metadata": {
        "id": "6ca590ab"
      },
      "outputs": [],
      "source": [
        "def results(y_test, y_pred, y_pred_prob):\n",
        "    test_fpr, test_tpr, _ = roc_curve(y_test, y_pred_prob)\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
        "    roc = roc_auc_score(y_test, y_pred)\n",
        "    return test_fpr,test_tpr,precision,recall,roc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15994a7c",
      "metadata": {
        "id": "15994a7c"
      },
      "source": [
        "## Unbalanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c381f46",
      "metadata": {
        "id": "1c381f46"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2, test_size=0.30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4cc07dd",
      "metadata": {
        "scrolled": false,
        "id": "d4cc07dd"
      },
      "outputs": [],
      "source": [
        "# Decision Tree performance\n",
        "model_DT = DT_pred(X_train, y_train)\n",
        "\n",
        "y_pred = model_DT.predict(X_test)\n",
        "y_pred_prob = model_DT.predict_proba(X_test)\n",
        "y_pred_prob = y_pred_prob[:, 1]\n",
        "\n",
        "dt_fpr,dt_tpr,dt_prec,dt_rec,dt_roc = results(y_test, y_pred, y_pred_prob)\n",
        "\n",
        "plot_performance(y_test, y_pred, y_pred_prob)\n",
        "plot_confusion(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe2256c9",
      "metadata": {
        "scrolled": false,
        "id": "fe2256c9"
      },
      "outputs": [],
      "source": [
        "# Random Forest performance\n",
        "model_RF = RF_pred_gpu(X_train, y_train)\n",
        "y_pred = model_RF.predict(X_test)\n",
        "y_pred_prob = model_RF.predict_proba(X_test)\n",
        "y_pred_prob = y_pred_prob[:, 1]\n",
        "\n",
        "rf_fpr,rf_tpr,rf_prec,rf_rec,rf_roc = results(y_test, y_pred, y_pred_prob)\n",
        "\n",
        "\n",
        "plot_performance(y_test, y_pred, y_pred_prob)\n",
        "plot_confusion(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db24ef44",
      "metadata": {
        "scrolled": false,
        "id": "db24ef44"
      },
      "outputs": [],
      "source": [
        "\n",
        "# LGB performance\n",
        "model_LGB = LGB_pred(X_train, y_train)\n",
        "\n",
        "y_pred = model_LGB.predict(X_test)\n",
        "y_pred_prob = model_LGB.predict_proba(X_test)\n",
        "y_pred_prob = y_pred_prob[:, 1]\n",
        "\n",
        "lgb_fpr,lgb_tpr,lgb_prec,lgb_rec,lgb_roc = results(y_test, y_pred, y_pred_prob)\n",
        "\n",
        "plot_performance(y_test, y_pred, y_pred_prob)\n",
        "plot_confusion(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d159e2eb",
      "metadata": {
        "id": "d159e2eb"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a464718",
      "metadata": {
        "id": "7a464718"
      },
      "outputs": [],
      "source": [
        "dic = {'classifiers':['Decision Tree','Random Forest','LightGBM'],\n",
        "      'fpr':[dt_fpr,rf_fpr,lgb_fpr],'tpr':[dt_tpr,rf_tpr,lgb_tpr],'auc':[dt_roc,rf_roc,lgb_roc]}\n",
        "res_df = pd.DataFrame(dic)\n",
        "res_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93dfb06b",
      "metadata": {
        "id": "93dfb06b"
      },
      "outputs": [],
      "source": [
        "res_df.set_index('classifiers', inplace=True)\n",
        "res_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92cd1c43",
      "metadata": {
        "scrolled": false,
        "id": "92cd1c43"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8,6))\n",
        "\n",
        "for i in res_df.index:\n",
        "    plt.plot(res_df.loc[i]['fpr'],\n",
        "             res_df.loc[i]['tpr'],\n",
        "             label=\"{}, AUC={:.3f}\".format(i, res_df.loc[i]['auc']))\n",
        "\n",
        "plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
        "\n",
        "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
        "plt.legend(prop={'size':13}, loc='lower right')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "055fad7b",
      "metadata": {
        "id": "055fad7b"
      },
      "outputs": [],
      "source": [
        "print(lgb_prec,lgb_rec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d66479a",
      "metadata": {
        "id": "4d66479a"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "ax.plot( dt_rec,dt_prec, label='Decision Tree')\n",
        "ax.plot( rf_rec,rf_prec, label='Random Forest')\n",
        "ax.plot(lgb_rec, lgb_prec, label='LightGBM')\n",
        "\n",
        "baseline = len(y_test[y_test==1]) / len(y_test)\n",
        "ax.plot([0, 1], [baseline, baseline], linestyle='--', label='Baseline')\n",
        "ax.set_xlabel('Recall')\n",
        "ax.set_ylabel('Precision')\n",
        "ax.set_title('Precision Recall Curve')\n",
        "ax.legend(loc='center left');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70e371fe",
      "metadata": {
        "id": "70e371fe"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm= confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=[10,8])\n",
        "plt.title('Confusion matrix of the LightGBM classifier')\n",
        "sns.heatmap(cm,annot=True,fmt=\".1f\")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.ioff()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95d7d9cc",
      "metadata": {
        "id": "95d7d9cc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d288aac",
      "metadata": {
        "id": "1d288aac"
      },
      "outputs": [],
      "source": [
        "print('Precision: %.3f' % precision_score(y_test, y_pred))\n",
        "print('Recall: %.3f' % recall_score(y_test, y_pred))\n",
        "print('F1-Score: %.3f' % f1_score(y_test, y_pred))\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34356470",
      "metadata": {
        "id": "34356470"
      },
      "source": [
        "## Balanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8ddaf38",
      "metadata": {
        "id": "c8ddaf38"
      },
      "outputs": [],
      "source": [
        "sm = SMOTE(random_state=4)\n",
        "X_smote, y_smote = SMOTE().fit_sample(X, y)\n",
        "\n",
        "print(\"Original data distribution: \")\n",
        "print(y.label.value_counts())\n",
        "print(\"SMOTE data distribution: \")\n",
        "print(y_smote.label.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80405f94",
      "metadata": {
        "id": "80405f94"
      },
      "outputs": [],
      "source": [
        "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X, y, random_state=2, test_size=0.30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8c0ead9",
      "metadata": {
        "scrolled": false,
        "id": "f8c0ead9"
      },
      "outputs": [],
      "source": [
        "# Decision Tree performance\n",
        "model_DT_bal = DT_pred(X_train_bal, y_train_bal)\n",
        "\n",
        "y_pred_bal = model_DT_bal.predict(X_test_bal)\n",
        "y_pred_prob_bal = model_DT_bal.predict_proba(X_test_bal)\n",
        "y_pred_prob_bal = y_pred_prob_bal[:, 1]\n",
        "\n",
        "dt_fpr_bal,dt_tpr_bal,dt_prec_bal,dt_rec_bal,dt_roc_bal = results(y_test_bal, y_pred_bal, y_pred_prob_bal)\n",
        "\n",
        "plot_performance(y_test_bal, y_pred_bal, y_pred_prob_bal)\n",
        "plot_confusion(y_test_bal, y_pred_bal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae05b4c2",
      "metadata": {
        "scrolled": false,
        "id": "ae05b4c2"
      },
      "outputs": [],
      "source": [
        "# Random Forest performance\n",
        "model_RF_bal = RF_pred(X_train_bal, y_train_bal)\n",
        "y_pred_bal = model_RF_bal.predict(X_test_bal)\n",
        "y_pred_prob_bal = model_RF_bal.predict_proba(X_test_bal)\n",
        "y_pred_prob_bal = y_pred_prob_bal[:, 1]\n",
        "\n",
        "rf_fpr_bal,rf_tpr_bal,rf_prec_bal,rf_rec_bal,rf_roc_bal = results(y_test_bal, y_pred_bal, y_pred_prob_bal)\n",
        "\n",
        "\n",
        "plot_performance(y_test_bal, y_pred_bal, y_pred_prob_bal)\n",
        "plot_confusion(y_test_bal, y_pred_bal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "773a8df7",
      "metadata": {
        "scrolled": false,
        "id": "773a8df7"
      },
      "outputs": [],
      "source": [
        "# LGB performance\n",
        "model_LGB_bal = LGB_pred(X_train_bal, y_train_bal)\n",
        "\n",
        "y_pred_bal = model_LGB_bal.predict(X_test_bal)\n",
        "y_pred_prob_bal = model_LGB_bal.predict_proba(X_test_bal)\n",
        "y_pred_prob_bal = y_pred_prob_bal[:, 1]\n",
        "\n",
        "lgb_fpr_bal,lgb_tpr_bal,lgb_prec_bal,lgb_rec_bal,lgb_roc_bal = results(y_test_bal, y_pred_bal, y_pred_prob_bal)\n",
        "\n",
        "plot_performance(y_test_bal, y_pred_bal, y_pred_prob_bal)\n",
        "plot_confusion(y_test_bal, y_pred_bal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1ZEBe2w3ZTj"
      },
      "source": [],
      "id": "H1ZEBe2w3ZTj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDRYNESv3ZTo"
      },
      "outputs": [],
      "source": [
        "dic = {'classifiers':['Decision Tree','Random Forest','LightGBM'],\n",
        "      'fpr':[dt_fpr_bal,rf_fpr_bal,lgb_fpr_bal],'tpr':[dt_tpr_bal,rf_tpr_bal,lgb_tpr_bal],\n",
        "       'auc':[dt_roc_bal,rf_roc_bal,lgb_roc_bal]}\n",
        "res_df_bal = pd.DataFrame(dic)\n",
        "res_df_bal"
      ],
      "id": "KDRYNESv3ZTo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVDaQOaB3ZTo"
      },
      "outputs": [],
      "source": [
        "res_df_bal.set_index('classifiers', inplace=True)\n",
        "res_df_bal"
      ],
      "id": "aVDaQOaB3ZTo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "YomVLS4u3ZTo"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8,6))\n",
        "\n",
        "for i in res_df_bal.index:\n",
        "    plt.plot(res_df_bal.loc[i]['fpr'],\n",
        "             res_df_bal.loc[i]['tpr'],\n",
        "             label=\"{}, AUC={:.3f}\".format(i, res_df_bal.loc[i]['auc']))\n",
        "\n",
        "plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
        "\n",
        "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
        "plt.legend(prop={'size':13}, loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "id": "YomVLS4u3ZTo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Klmpw66U3ZTo"
      },
      "outputs": [],
      "source": [
        "print(lgb_prec_bal,lgb_rec_bal)"
      ],
      "id": "Klmpw66U3ZTo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXpqR4SM3ZTo"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "ax.plot( dt_rec_bal,dt_prec_bal, label='Decision Tree')\n",
        "ax.plot( rf_rec_bal,rf_prec_bal, label='Random Forest')\n",
        "ax.plot(lgb_rec_bal, lgb_prec_bal, label='LightGBM')\n",
        "\n",
        "baseline = len(y_test_bal[y_test_bal==1]) / len(y_test_bal)\n",
        "ax.plot([0, 1], [baseline, baseline], linestyle='--', label='Baseline')\n",
        "ax.set_xlabel('Recall')\n",
        "ax.set_ylabel('Precision')\n",
        "ax.set_title('Precision Recall Curve')\n",
        "ax.legend(loc='center left');"
      ],
      "id": "rXpqR4SM3ZTo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtCoIiGx3ZTo"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm= confusion_matrix(y_test_bal, y_pred_bal)\n",
        "plt.figure(figsize=[10,8])\n",
        "plt.title('Confusion matrix of the LightGBM classifier')\n",
        "sns.heatmap(cm,annot=True,fmt=\".1f\")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.ioff()\n",
        "plt.show()"
      ],
      "id": "DtCoIiGx3ZTo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0Zb4dTY3ZTo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ],
      "id": "W0Zb4dTY3ZTo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4Pul1sC3ZTo"
      },
      "outputs": [],
      "source": [
        "print('Precision: %.3f' % precision_score(y_test_bal, y_pred_bal))\n",
        "print('Recall: %.3f' % recall_score(y_test_bal, y_pred_bal))\n",
        "print('F1-Score: %.3f' % f1_score(y_test_bal, y_pred_bal))\n",
        "print('Accuracy: %.3f' % accuracy_score(y_test_bal, y_pred_bal))"
      ],
      "id": "j4Pul1sC3ZTo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "625cd99f",
      "metadata": {
        "id": "625cd99f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0a79f428",
      "metadata": {
        "id": "0a79f428"
      },
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b09a9721",
      "metadata": {
        "id": "b09a9721"
      },
      "source": [
        "https://machinelearningmastery.com/feature-selection-machine-learning-python/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a821fb96",
      "metadata": {
        "id": "a821fb96"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Feature Selection with Univariate Statistical Tests\n",
        "from pandas import read_csv\n",
        "from numpy import set_printoptions\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "625aa528",
      "metadata": {
        "id": "625aa528"
      },
      "outputs": [],
      "source": [
        "importance = model_LGB.feature_importances_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee078770",
      "metadata": {
        "id": "ee078770"
      },
      "outputs": [],
      "source": [
        "def plot_feature_importance(importance,names,model_type):\n",
        "\n",
        "    #Create arrays from feature importance and feature names\n",
        "    feature_importance = np.array(importance)\n",
        "    feature_names = np.array(names)\n",
        "\n",
        "    #Create a DataFrame using a Dictionary\n",
        "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
        "    fi_df = pd.DataFrame(data)\n",
        "\n",
        "    #Sort the DataFrame in order decreasing feature importance\n",
        "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
        "\n",
        "    #Define size of bar plot\n",
        "    plt.figure(figsize=(8,6))\n",
        "    #Plot Searborn bar chart\n",
        "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
        "    #Add chart labels\n",
        "    plt.title(model_type + 'FEATURE IMPORTANCE')\n",
        "    plt.xlabel('FEATURE IMPORTANCE')\n",
        "    plt.ylabel('FEATURE NAMES')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce20559f",
      "metadata": {
        "scrolled": false,
        "id": "ce20559f"
      },
      "outputs": [],
      "source": [
        "plot_feature_importance(model_LGB.feature_importances_,X.columns,'LightGBM ')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vd49FeRRSgXd"
      },
      "id": "vd49FeRRSgXd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "myenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}